{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of Copy of Divorce Predictors Analytics.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niltontac/EspAnalise-EngDados/blob/master/Divorce_Predictors_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC8Do551jTvP",
        "colab_type": "text"
      },
      "source": [
        "#Sobre este Conjunto de Dados\n",
        "# **About this Data Set:**\n",
        "\n",
        "###### Neste conjunto de dados, a predição de divórcio foi realizada usando uma Escala de Preditores de Divócio (DPS) baseada no método Gottman de terapia de casais. Do total de 170 participantes, 84 eram divorciados e 86 casados. Os participantes preencheram o \"Formulário de Informações Pessoais\" da DPS.\n",
        "###### A ideia da minha análise é mostrar, baseada nas respostas das pessoas, a probabilidade delas serem casadas ou divorciadas de acordo com o que foi preenchido. No final também mostro o nível de precisão de minha análise.\n",
        "-----------------------------------------\n",
        "###### Within the scope of this research, the divorce prediction was carried out by using the Divorce Predictors Scale (DPS) on the basis of Gottman couples therapy. Of the participants, 84 (49%) were divorced and 86 (51%) were married couples. Participants completed the “Personal Information Form” from DPS. \n",
        "###### The idea of my analysis is to show, based on people's answers, the probabilitly of them being married or divorced, according to what was filled out. At the end also show accuracy level of my analysis.\n",
        "-----------------------------------------\n",
        "###### Fonte | Source: https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set\n",
        "###### Arquivo | File: divorce.csv  \n",
        "-----------------------------------------\n",
        "# Analista | Analyst: Nilton Thiago de Andrade Coura - Matrícula 3376\n",
        "### Especialização em Análise e Engenharia de Dados - Cesar School/CInUFPE\n",
        "#### Disciplina: Estatística Descritiva dos Dados\n",
        "##### Professor:  Tsang Ing Ren | CIn/UFPE\n",
        "###### Monitor: José Ivson Silva | CIn/UFPE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tr5vBBMsHo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando bibliotecas\n",
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "\n",
        "# Carregando arquivo divorce.csv que contém o conjunto de dados que será analisado\n",
        "# Loading dataset file\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/niltontac/EspAnalise-EngDados/master/data/Divorce_Predictors_Dataset.csv', sep=';', decimal=',', thousands='.', encoding='ISO-8859-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62hIhs5ws-sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizando uma \"amostragem\" do conjunto de dados\n",
        "\n",
        "# \"Atr1\", \"Atr2\", \"Atr3\",..., Atr38, AtrN... são as colunas do conjunto. Cada coluna representa uma resposta de cada pergunta respondida \n",
        "# dos participantes, esses representados por cada linha do index (que começa com 0)\n",
        "\n",
        "# \"Class\" é a coluna que corresponde se o participante é casado ou divorciado. Onde \"1\" corresponde a divorcidado e \"0\" a casado\n",
        "\n",
        "# As respostas dos participantes foram classificadas assim: \n",
        "# 0 - não relevante | 1 - pouco relevante | 2 - relevante | 3 - muito relevante | 4 - extremamente relevante\n",
        "\n",
        "# Dataset sample\n",
        "\n",
        "# Columns Atr1, Atr2, Atr3,..., AtrN... tell answers from stakeholders\n",
        "\n",
        "# Column \"Class\" corresponds to wheter the participant is married or divorced. Which \"1\" corresponds to divorced and \"0\" to married\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgRv1p_qm4LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimensão do conjunto de dados - linhas x colunas\n",
        "\n",
        "# Data set size - rows vs columns\n",
        "\n",
        "print(\"rows, columns\", df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSJDE7b-wHrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 54 perguntas em 54 colunas (cada pergunta é uma coluna)\n",
        "# 54 questions in 54 colmns\n",
        "questions_list = ['Atr1','Atr2','Atr3','Atr4','Atr5','Atr6','Atr7','Atr8','Atr9','Atr10','Atr11','Atr12','Atr13','Atr14','Atr15','Atr16','Atr17','Atr18','Atr19','Atr20','Atr21','Atr22','Atr23','Atr24','Atr25','Atr26','Atr27','Atr28','Atr29','Atr30','Atr31','Atr32','Atr33','Atr34','Atr35','Atr36','Atr37','Atr38','Atr39','Atr40','Atr41','Atr42','Atr43','Atr44','Atr45','Atr46','Atr47','Atr48','Atr49','Atr50','Atr51','Atr52','Atr53','Atr54']\n",
        "\n",
        "# Truncando 8 colunas de onde o sistema irá selecionar as perguntas de cada coluna de forma aleatória\n",
        "# Selecting 8 random questions from columns \n",
        "truncate_question = np.random.randint(low=0, high=53, size=7)\n",
        "\n",
        "# Concatenando as colunas numa lista\n",
        "# Concatenating list colmns\n",
        "dataset = df.loc[:,['Atr'+str(truncate_question[0]), 'Atr'+str(truncate_question[1]), 'Atr'+str(truncate_question[2]), 'Atr'+str(truncate_question[3]), 'Atr'+str(truncate_question[4]), 'Atr'+str(truncate_question[5]), 'Atr'+str(truncate_question[6]), 'Class']]\n",
        "\n",
        "# Imprimindo as colunas escolhidas pelo sistema de forma aleatória\n",
        "# Printing random questions\n",
        "print(\"truncate_question: \", truncate_question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFmcD6GjGiv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confirmando truncamento\n",
        "# Confirming truncation\n",
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMCCFvurn-0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimensão do conjunto de dados pronto para realização de análise\n",
        "\n",
        "# Size of the data set ready to analysis\n",
        "\n",
        "print(\"rows, columns\", dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzASoDAuN71H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Função que mostra separadamente a quantidade dos participantes casados (valores 0 em 86 linhas) dos divorciados (valores 1 em 84 linhas) contidas na coluna \"Class\"\n",
        "\n",
        "# Function to separate by class between married( values 0 | 86 rows ) and divorced(values 1 | 84 rows)\n",
        "\n",
        "def separate_by_class(dataset):\n",
        "  classes = np.unique(dataset['Class'])\n",
        "\n",
        "  separated = []\n",
        "  for cl in classes:\n",
        "    separated.append(dataset[dataset['Class'] == cl])\n",
        "\n",
        "  return separated\n",
        "\n",
        "separated = separate_by_class(dataset)\n",
        "print(separated)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_0g1WUzLlQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sumarizar para agrupar e calcular dados estatísticos de cada coluna (que contem as respostas dos participantes referentes as perguntas das colunas selecionadas aleatoriamente pelo sistema) \n",
        "# do dataset (nesse caso eliminando a coluna \"Class\" que é a coluna que contém o resultado probabilístico em função dos dados calculados pelas características das respostas).\n",
        "# Cálculo da média, do desvio padrão e da quantidade total de participantes\n",
        "\n",
        "# Summarize data - Calculate the mean, std and count for each column in a dataset\n",
        "\n",
        "def summarize_dataset(dataset, eliminate_last=True):\n",
        "  if eliminate_last:\n",
        "    columns = dataset.columns[:-1]\n",
        "  else:\n",
        "    columns = dataset.columns\n",
        "  summaries = [(np.mean(dataset[column]), np.std(dataset[column]), len(dataset[column])) for column in dataset.columns]\n",
        "  del(summaries[-1])\n",
        "  return summaries\n",
        "\n",
        "summaries = summarize_dataset(dataset)\n",
        "\n",
        "print(summaries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51yWG3NuMJK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Novamente sumarizando e agrupando o dataset para calcular dados estatísticos (média, desvio padrão e a quantidade total de participantes). \n",
        "# Mas nesse caso queremos especificamente trazer apenas os resultados da coluna \"Class\". Os valores probabilísticos já foram calculados na função acima \"def summarize_dataset\", \n",
        "# e os resultados guardados na variável \"summaries\"\n",
        "\n",
        "# Summarize data by class\n",
        "\n",
        "def summarize_by_class(dataset):\n",
        "  separated = separate_by_class(dataset)\n",
        "  summaries = dict()\n",
        "  for s in separated:\n",
        "    class_value = np.array(s['Class'])\n",
        "    rows = s[s.columns]\n",
        "    summaries[class_value[0]] = summarize_dataset(rows, eliminate_last=False)\n",
        "  return summaries\n",
        "\n",
        "summaries_by_class = summarize_by_class(dataset)\n",
        "print(summaries_by_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF22J8YOJkA2",
        "colab_type": "text"
      },
      "source": [
        "#Probabilidade Gaussiana\n",
        "\n",
        "Gaussian Probabilitly\n",
        "\n",
        "$\n",
        "f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{(x-\\mu)}{\\sigma})^2}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBzumoJOMZVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definindo a função 'calculate_probabilitly' que vai calcular a probabilidade usando a distribuição Gaussiana\n",
        "\n",
        "# Gaussian Probabilitly - f(x)=1σ2π√e−12((x−μ)σ)2\n",
        "\n",
        "def calculate_probability(x, mean, stdev):\n",
        "\texponent = np.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
        "\treturn (1 / (np.sqrt(2 * np.pi) * stdev)) * exponent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5RQxqCWMqDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Probabilidade de distribuição por divórcio\n",
        "\n",
        "# Probabilitly distribution by Divorce\n",
        "\n",
        "x = np.arange(-4.5,10,0.1)\n",
        "for summ in summaries:\n",
        "  y = calculate_probability(x, summ[0], summ[1])\n",
        "  plt.plot(x,y)\n",
        "\n",
        "plt.legend(['Atr'+str(truncate_question[0]), 'Atr'+str(truncate_question[1]), 'Atr'+str(truncate_question[2]), 'Atr'+str(truncate_question[3]), 'Atr'+str(truncate_question[4]), 'Atr'+str(truncate_question[5]), 'Atr'+str(truncate_question[6])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig42YOz2Ur1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Probabilidade de distribuição por classe\n",
        "\n",
        "# Probabilitly distribution by class\n",
        "\n",
        "n_classes = len(summaries_by_class)\n",
        "fig,ax = plt.subplots(1,n_classes)\n",
        "fig.set_size_inches(18, h=6)\n",
        "\n",
        "classes_name = ['Married', 'Divorced']\n",
        "for c in range(n_classes):\n",
        "  for summ in summaries_by_class[c]:\n",
        "    ax[c].plot(x, calculate_probability(x, summ[0], summ[1]))\n",
        "  ax[c].set_title(classes_name[c])\n",
        "\n",
        "fig.legend(['Atr'+str(truncate_question[0]), 'Atr'+str(truncate_question[1]), 'Atr'+str(truncate_question[2]), 'Atr'+str(truncate_question[3]), 'Atr'+str(truncate_question[4]), 'Atr'+str(truncate_question[5]), 'Atr'+str(truncate_question[6])])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa8FpaJIubmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cálculo percentual de precisão\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGrmuZHRqAoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cálculo da probabilidade de predição\n",
        "\n",
        "# Calculate the probabilities of predicting \n",
        "\n",
        "def calculate_class_probabilities(summaries, row):\n",
        "  total_rows = sum([summaries[label][0][2] for label in summaries])\n",
        "  probabilities = dict()\n",
        "  for class_value, class_summaries in summaries.items():\n",
        "    probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
        "    for i in range(len(class_summaries)):\n",
        "      mean, stdev, count = class_summaries[i]\n",
        "      probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
        "  return probabilities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALwlsOPwuQqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predição da classe para determinada linha\n",
        "\n",
        "# Predict the class for a given row\n",
        "\n",
        "def predict(summaries, row):\n",
        "\n",
        "\tprobabilities = calculate_class_probabilities(summaries, row)\n",
        "\tbest_label, best_prob = None, -1\n",
        "\tfor class_value, probability in probabilities.items():\n",
        "\t\tif best_label is None or probability > best_prob:\n",
        "\t\t\tbest_prob = probability\n",
        "\t\t\tbest_label = class_value\n",
        "\treturn best_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehhiSFcjLWq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dividindo o dataset\n",
        "\n",
        "# Split the dataset\n",
        "\n",
        "def split(dataset):\n",
        "  sz = dataset.shape[0]\n",
        "  sh = np.arange(sz)\n",
        "  np.random.shuffle(sh)\n",
        "  vec = np.zeros((sz),dtype=bool)\n",
        "  vec[sh[:int(sz*0.75)]] = True\n",
        "  train = dataset.loc[vec]\n",
        "  test = dataset.loc[~vec]\n",
        "\n",
        "  return train, test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2H8yCmLXn4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,test = split(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4sYcp9qxScD",
        "colab_type": "text"
      },
      "source": [
        "#Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOGM8TwiuFJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Naive Bayes Algorithm\n",
        "def naive_bayes(train, test):\n",
        "  summarize = summarize_by_class(train)\n",
        "  predictions = list()\n",
        "  vec = np.zeros(test.shape[0], dtype=bool)\n",
        "  for i in range(test.shape[0]):\n",
        "    vec[i] = True\n",
        "    row = np.array(test.loc[vec])[0]\n",
        "    output = predict(summarize, row)\n",
        "    predictions.append(output)\n",
        "    vec[i] = False\n",
        "  return(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx9QaXP0M8gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = naive_bayes(train,test)\n",
        "\n",
        "print(predictions)\n",
        "actual = np.array(test['Class'])\n",
        "print(actual)\n",
        "\n",
        "print('Accuracy ', accuracy_metric(actual, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}